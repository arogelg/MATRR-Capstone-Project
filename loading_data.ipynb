{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master file:\n",
      "  Species Cohort MATRR ID  Date of BC      Timepoint    State  TP:  ALB:  \\\n",
      "0    cyno      2    10016   8/17/2005  pre-induction  sedated  7.4   NaN   \n",
      "1    cyno      2    10016    2/6/2006  H2O induction    awake  NaN   NaN   \n",
      "2    cyno      2    10016   3/27/2006  H2O induction  sedated    7   4.2   \n",
      "3    cyno      2    10016  10/26/2006  open access 1  sedated  7.9   4.6   \n",
      "4    cyno      2    10016   4/18/2007  open access 2  sedated    7   4.2   \n",
      "\n",
      "   ALKP:  ALT:  ...  BASO%:  HCT:  HGB:  RBC:  MCV:  MCH:  MCHC:   PLT:  \\\n",
      "0    NaN   NaN  ...     0.7  43.5  14.3  6.05  72.0  23.6   32.9  426.0   \n",
      "1    NaN   NaN  ...     0.7  44.1  14.1  5.90  75.0  23.9   32.0  167.0   \n",
      "2  167.0  45.0  ...     0.8  42.8  13.9  5.73  75.0  24.3   32.5  378.0   \n",
      "3   84.0  37.0  ...     0.5  42.5  13.7  5.66  75.0  24.2   32.2  446.0   \n",
      "4  138.0  25.0  ...     0.9  42.9  13.5  5.63  76.0  24.0   31.5  214.0   \n",
      "\n",
      "   Unnamed: 44        Unnamed: 45  \n",
      "0          NaN  LY% = Lymphocytes  \n",
      "1          NaN                NaN  \n",
      "2          NaN                NaN  \n",
      "3          NaN                NaN  \n",
      "4          NaN                NaN  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "\n",
      "Biomarker file:\n",
      "        ID Drinking Category Species Sex       Age  Cortisol  ACTH  \\\n",
      "0  10069.0               VHD  Rhesus   F  4.136977       NaN   NaN   \n",
      "1  10070.0               VHD  Rhesus   F  4.117812       NaN   NaN   \n",
      "2  10072.0                LD  Rhesus   F  5.834480       NaN   NaN   \n",
      "3  10073.0               VHD  Rhesus   F  5.629137       NaN   NaN   \n",
      "4  10074.0                LD  Rhesus   F  5.585330       NaN   NaN   \n",
      "\n",
      "   Deoxycorticosterone  Aldosterone  DHEAS  ...  MIFAnalyte_46       IL_1RA  \\\n",
      "0                  NaN          NaN    NaN  ...      92.381481   436.517067   \n",
      "1                  NaN          NaN    NaN  ...      81.748359   495.060658   \n",
      "2                  NaN          NaN    NaN  ...      25.171621  1895.472706   \n",
      "3                  NaN          NaN    NaN  ...      11.968421   377.229597   \n",
      "4                  NaN          NaN    NaN  ...      27.572010  2035.124018   \n",
      "\n",
      "       TNF_a        IL_2     IP_10         MIG      IL_4      IL_8  \\\n",
      "0  31.596474  204.310168  2.293394  303.533753  3.913593  0.290000   \n",
      "1  54.033872  497.809677  1.588706  307.364482  2.984589  0.290000   \n",
      "2  16.848129   97.404725  2.292832   19.797336  2.408287  0.395192   \n",
      "3  10.366293   33.328021  0.984545   23.738633  0.814232  0.200000   \n",
      "4  23.880953  143.246838  6.181451   51.158897  2.408287  0.200000   \n",
      "\n",
      "        IL_23    VEGF_D  \n",
      "0  204.310168  0.059000  \n",
      "1  497.809677  0.059000  \n",
      "2   97.404725  0.378840  \n",
      "3   33.328021  0.072519  \n",
      "4  143.246838  0.797476  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "\n",
      "Monkey Data file:\n",
      "   mky_id  cohort_name mky_gender  mky_weight drinking_category  bec_exper  \\\n",
      "0   10005  INIA Cyno 1          M        4.95                LD        NaN   \n",
      "1   10005  INIA Cyno 1          M        4.95                LD        NaN   \n",
      "2   10005  INIA Cyno 1          M        4.95                LD        NaN   \n",
      "3   10005  INIA Cyno 1          M        4.95                LD        NaN   \n",
      "4   10005  INIA Cyno 1          M        4.95                LD        NaN   \n",
      "\n",
      "   bec_exper_day bec_sample  bec_gkg_etoh  bec_daily_gkg_etoh  ...  \\\n",
      "0           24.0   11:46:00          0.29                0.51  ...   \n",
      "1           24.0   11:46:00          0.29                0.51  ...   \n",
      "2           24.0   11:46:00          0.29                0.51  ...   \n",
      "3           24.0   11:46:00          0.29                0.51  ...   \n",
      "4           24.0   11:46:00          0.29                0.51  ...   \n",
      "\n",
      "   ebt_number  ebt_start_time  ebt_end_time  ebt_intake_rate  ebt_length  \\\n",
      "0         1.0            37.0         114.0         0.200200        77.0   \n",
      "1         7.0          5861.0        5870.0         0.266667         9.0   \n",
      "2         2.0           463.0         463.0         0.230769         1.0   \n",
      "3         3.0           976.0        1285.0         0.005377       309.0   \n",
      "4         4.0          2106.0        2106.0         0.276923         1.0   \n",
      "\n",
      "   mtd_etoh_intake  mtd_pct_etoh  mtd_veh_intake  mtd_total_pellets  \\\n",
      "0             66.3         14.07           405.0               90.0   \n",
      "1             66.3         14.07           405.0               90.0   \n",
      "2             66.3         14.07           405.0               90.0   \n",
      "3             66.3         14.07           405.0               90.0   \n",
      "4             66.3         14.07           405.0               90.0   \n",
      "\n",
      "   mtd_etoh_conc  \n",
      "0           0.04  \n",
      "1           0.04  \n",
      "2           0.04  \n",
      "3           0.04  \n",
      "4           0.04  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv files\n",
    "master = pd.read_csv('csv files/10_23_2024_MASTER_MATRR_AllCohorts_Blood_hematology_biochemistry.csv')\n",
    "\n",
    "# Read the master file. If the CSV has a header row, pandas will use it.\n",
    "master_df =pd.read_csv('csv files/10_23_2024_MASTER_MATRR_AllCohorts_Blood_hematology_biochemistry.csv')\n",
    "\n",
    "# Read the biomarker crosstime points file\n",
    "biomarker_df = pd.read_csv(\"csv files/Biomarker Cross Timepoints.csv\")\n",
    "\n",
    "# Read the Monkey Data\n",
    "monkey_df = pd.read_csv(\"csv files/Monkey Data Cohorts Capstone.csv\")\n",
    "\n",
    "# Check the first few rows of each to verify they loaded correctly\n",
    "print(\"Master file:\")\n",
    "print(master_df.head(5))\n",
    "\n",
    "print(\"\\nBiomarker file:\")\n",
    "print(biomarker_df.head(5))\n",
    "\n",
    "print(\"\\nMonkey Data file:\")\n",
    "print(monkey_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mky_id</th>\n",
       "      <th>mky_weight</th>\n",
       "      <th>bec_exper</th>\n",
       "      <th>bec_exper_day</th>\n",
       "      <th>bec_gkg_etoh</th>\n",
       "      <th>bec_daily_gkg_etoh</th>\n",
       "      <th>bec_mg_pct</th>\n",
       "      <th>ebt_number</th>\n",
       "      <th>ebt_start_time</th>\n",
       "      <th>ebt_end_time</th>\n",
       "      <th>ebt_intake_rate</th>\n",
       "      <th>ebt_length</th>\n",
       "      <th>mtd_etoh_intake</th>\n",
       "      <th>mtd_pct_etoh</th>\n",
       "      <th>mtd_veh_intake</th>\n",
       "      <th>mtd_total_pellets</th>\n",
       "      <th>mtd_etoh_conc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>160584.000000</td>\n",
       "      <td>160583.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160574.000000</td>\n",
       "      <td>160574.000000</td>\n",
       "      <td>160536.000000</td>\n",
       "      <td>160574.000000</td>\n",
       "      <td>160088.000000</td>\n",
       "      <td>160088.000000</td>\n",
       "      <td>160088.000000</td>\n",
       "      <td>150742.000000</td>\n",
       "      <td>160088.000000</td>\n",
       "      <td>160483.000000</td>\n",
       "      <td>151652.000000</td>\n",
       "      <td>158085.000000</td>\n",
       "      <td>160489.000000</td>\n",
       "      <td>1.516520e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10144.804638</td>\n",
       "      <td>8.271772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.781092</td>\n",
       "      <td>2.070227</td>\n",
       "      <td>48.312649</td>\n",
       "      <td>80.082035</td>\n",
       "      <td>11.074753</td>\n",
       "      <td>25373.211609</td>\n",
       "      <td>25574.274999</td>\n",
       "      <td>0.184825</td>\n",
       "      <td>201.206474</td>\n",
       "      <td>510.367584</td>\n",
       "      <td>39.767020</td>\n",
       "      <td>974.607884</td>\n",
       "      <td>109.864171</td>\n",
       "      <td>4.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>112.400381</td>\n",
       "      <td>2.221240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.850519</td>\n",
       "      <td>1.205222</td>\n",
       "      <td>206.452605</td>\n",
       "      <td>71.974112</td>\n",
       "      <td>8.044851</td>\n",
       "      <td>25125.716404</td>\n",
       "      <td>25068.737091</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>462.681883</td>\n",
       "      <td>308.069509</td>\n",
       "      <td>21.774274</td>\n",
       "      <td>661.009226</td>\n",
       "      <td>43.422157</td>\n",
       "      <td>1.444445e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10005.000000</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10045.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7475.000000</td>\n",
       "      <td>7674.000000</td>\n",
       "      <td>0.039245</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>297.600000</td>\n",
       "      <td>24.689225</td>\n",
       "      <td>455.600000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>4.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10088.000000</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.710000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16598.000000</td>\n",
       "      <td>16858.000000</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>484.500000</td>\n",
       "      <td>35.199060</td>\n",
       "      <td>927.600000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>4.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10247.000000</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28751.750000</td>\n",
       "      <td>28844.000000</td>\n",
       "      <td>0.234528</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>692.500000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>1435.600000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10359.000000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>1637.800000</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>79220.000000</td>\n",
       "      <td>79244.000000</td>\n",
       "      <td>212.188235</td>\n",
       "      <td>45204.000000</td>\n",
       "      <td>2265.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3649.400000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>4.000000e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mky_id     mky_weight  bec_exper  bec_exper_day   bec_gkg_etoh  \\\n",
       "count  160584.000000  160583.000000        0.0  160574.000000  160574.000000   \n",
       "mean    10144.804638       8.271772        NaN     265.781092       2.070227   \n",
       "std       112.400381       2.221240        NaN     196.850519       1.205222   \n",
       "min     10005.000000       2.640000        NaN       1.000000       0.000000   \n",
       "25%     10045.000000       7.200000        NaN     117.000000       1.400000   \n",
       "50%     10088.000000       8.240000        NaN     239.000000       2.000000   \n",
       "75%     10247.000000       9.840000        NaN     350.000000       2.680000   \n",
       "max     10359.000000      13.800000        NaN     937.000000      50.600000   \n",
       "\n",
       "       bec_daily_gkg_etoh     bec_mg_pct     ebt_number  ebt_start_time  \\\n",
       "count       160536.000000  160574.000000  160088.000000   160088.000000   \n",
       "mean            48.312649      80.082035      11.074753    25373.211609   \n",
       "std            206.452605      71.974112       8.044851    25125.716404   \n",
       "min              0.000000       0.000000       1.000000        0.000000   \n",
       "25%              1.880000      25.000000       5.000000     7475.000000   \n",
       "50%              2.710000      69.000000      10.000000    16598.000000   \n",
       "75%              3.800000     118.000000      16.000000    28751.750000   \n",
       "max           1637.800000     669.000000     118.000000    79220.000000   \n",
       "\n",
       "        ebt_end_time  ebt_intake_rate     ebt_length  mtd_etoh_intake  \\\n",
       "count  160088.000000    150742.000000  160088.000000    160483.000000   \n",
       "mean    25574.274999         0.184825     201.206474       510.367584   \n",
       "std     25068.737091         0.888537     462.681883       308.069509   \n",
       "min         0.000000         0.000000       1.000000        -1.000000   \n",
       "25%      7674.000000         0.039245       8.000000       297.600000   \n",
       "50%     16858.000000         0.109146      45.000000       484.500000   \n",
       "75%     28844.000000         0.234528     241.000000       692.500000   \n",
       "max     79244.000000       212.188235   45204.000000      2265.200000   \n",
       "\n",
       "        mtd_pct_etoh  mtd_veh_intake  mtd_total_pellets  mtd_etoh_conc  \n",
       "count  151652.000000   158085.000000      160489.000000   1.516520e+05  \n",
       "mean       39.767020      974.607884         109.864171   4.000000e-02  \n",
       "std        21.774274      661.009226          43.422157   1.444445e-10  \n",
       "min         0.000000       -1.000000          -1.000000   4.000000e-02  \n",
       "25%        24.689225      455.600000          84.000000   4.000000e-02  \n",
       "50%        35.199060      927.600000         117.000000   4.000000e-02  \n",
       "75%        49.600000     1435.600000         141.000000   4.000000e-02  \n",
       "max       100.000000     3649.400000         228.000000   4.000000e-02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monkey_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Species', 'Cohort', 'MATRR ID', 'Date of BC', 'Timepoint', 'State',\n",
       "       'TP:', 'ALB:', 'ALKP:', 'ALT:', 'AST:', 'GGT:', 'TBIL:', 'GLU:', 'BUN:',\n",
       "       'CREA:', 'K:', 'NA:', 'CL:', 'Ca:', 'PHOS:', 'Fe:', 'CHOL:', 'LDH:',\n",
       "       'TRIG:', 'A/G ratio:', 'DBIL:', 'Glob:', 'Amyl:', 'MG:', 'WBC:',\n",
       "       'NEUT%:', 'BAND%:', 'LY%', 'MONO%:', 'EOS%:', 'BASO%:', 'HCT:', 'HGB:',\n",
       "       'RBC:', 'MCV:', 'MCH:', 'MCHC:', 'PLT:', 'Unnamed: 44', 'Unnamed: 45'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop two columns that we wont need\n",
    "master_df = master_df.drop(columns=['Unnamed: 44', 'Unnamed: 45'])\n",
    "\n",
    "# Cleaning the master dataframe to keep only the open access 1 data (Were keeping onlye the first apparenace assuming thats exactly 60 days after the first open access)\n",
    "open_access_df = master_df.loc[(master_df['Timepoint'] == 'open access 1') | (master_df['Timepoint'] == 'open access')].drop_duplicates(subset=['MATRR ID', 'Timepoint'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(open_access_df['MATRR ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomarker_df = biomarker_df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to ensure all keys are strings to be able to use them as keys in case we need to merge our data later\n",
    "# We also need to clean the 'MATRR ID' column in master_df\n",
    "open_access_df['MATRR ID'] = open_access_df['MATRR ID'].astype(str) \\\n",
    "    .str.replace('\\xa0', '', regex=False) \\\n",
    "    .str.strip() \\\n",
    "    .str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "#We need to make the biomarker ID first be just an int not a float and theh a string\n",
    "biomarker_df[\"ID\"] = biomarker_df[\"ID\"].astype(int).astype(str)\n",
    "\n",
    "monkey_df['mky_id'] = monkey_df['mky_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common IDs in OA file and Monkey Data: 119\n",
      "IDs in OA file but not in Monkey Data: 66\n",
      "IDs in Monkey Data but not in OA file: 28\n"
     ]
    }
   ],
   "source": [
    "#First thing well do is check how many monkeys are in the master but not in the monkey data and vice versa\n",
    "unique_OA = set(open_access_df['MATRR ID'])\n",
    "unique_monkeys = set(monkey_df['mky_id'])\n",
    "\n",
    "common_OA_monkey = unique_OA & unique_monkeys\n",
    "\n",
    "\n",
    "print(\"Common IDs in OA file and Monkey Data:\", len(common_OA_monkey))\n",
    "\n",
    "ids_in_master_not_in_monkeys = unique_OA - unique_monkeys\n",
    "ids_in_monkey_not_in_master = unique_monkeys - unique_OA\n",
    "\n",
    "print(\"IDs in OA file but not in Monkey Data:\", len(ids_in_master_not_in_monkeys))\n",
    "print(\"IDs in Monkey Data but not in OA file:\", len(ids_in_monkey_not_in_master))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10255',\n",
       " '10352',\n",
       " '10353',\n",
       " '10354',\n",
       " '10355',\n",
       " '10356',\n",
       " '10357',\n",
       " '10358',\n",
       " '10359'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check the unique values of the raw master to ensure were not getting rid of anything important in our clean step before\n",
    "common_ids_clean = set(master_df['MATRR ID'].unique()) & set(monkey_df['mky_id'].unique())\n",
    "\n",
    "common_ids_clean - common_OA_monkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found an anomaly where a list of monkeys in the raw master were also in the monkey dataset but not in our clean master, we want to check one of those "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>MATRR ID</th>\n",
       "      <th>Date of BC</th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>State</th>\n",
       "      <th>TP:</th>\n",
       "      <th>ALB:</th>\n",
       "      <th>ALKP:</th>\n",
       "      <th>ALT:</th>\n",
       "      <th>...</th>\n",
       "      <th>MONO%:</th>\n",
       "      <th>EOS%:</th>\n",
       "      <th>BASO%:</th>\n",
       "      <th>HCT:</th>\n",
       "      <th>HGB:</th>\n",
       "      <th>RBC:</th>\n",
       "      <th>MCV:</th>\n",
       "      <th>MCH:</th>\n",
       "      <th>MCHC:</th>\n",
       "      <th>PLT:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>rhesus</td>\n",
       "      <td>16</td>\n",
       "      <td>10255</td>\n",
       "      <td>3/12/2018</td>\n",
       "      <td>baseline</td>\n",
       "      <td>sedated</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>269.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.48</td>\n",
       "      <td>11.60</td>\n",
       "      <td>4.64</td>\n",
       "      <td>65.65</td>\n",
       "      <td>24.99</td>\n",
       "      <td>38.06</td>\n",
       "      <td>446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>rhesus</td>\n",
       "      <td>16</td>\n",
       "      <td>10255</td>\n",
       "      <td>11/1/2018</td>\n",
       "      <td>1.5 g/kg etoh induction</td>\n",
       "      <td>sedated</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.62</td>\n",
       "      <td>11.79</td>\n",
       "      <td>4.82</td>\n",
       "      <td>71.87</td>\n",
       "      <td>24.47</td>\n",
       "      <td>34.05</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species Cohort MATRR ID Date of BC                Timepoint    State  TP:  \\\n",
       "793  rhesus     16    10255  3/12/2018                 baseline  sedated  6.5   \n",
       "794  rhesus     16    10255  11/1/2018  1.5 g/kg etoh induction  sedated  6.9   \n",
       "\n",
       "     ALB:  ALKP:  ALT:  ...  MONO%:  EOS%:  BASO%:   HCT:   HGB:  RBC:   MCV:  \\\n",
       "793   4.1  269.0  24.0  ...     NaN    NaN     NaN  30.48  11.60  4.64  65.65   \n",
       "794   4.0  146.0  34.0  ...     NaN    NaN     NaN  34.62  11.79  4.82  71.87   \n",
       "\n",
       "      MCH:  MCHC:   PLT:  \n",
       "793  24.99  38.06  446.0  \n",
       "794  24.47  34.05  311.0  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[master_df['MATRR ID'] == '10255']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see why its not in the clean master, this monkey does not have an 'open access' at all. For now well keep uisng clen but this is good to know. Lets proceed to check the before and after values to create the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 g/kg etoh induction       65\n",
      "H2O induction                 47\n",
      "pre-induction                 29\n",
      "etoh induction                17\n",
      "baseline                       9\n",
      "1.5 g/kg maltose induction     7\n",
      "1.0 g/kg etoh induction        5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# First, ensure the date column is in datetime format\n",
    "master_df[\"Date of BC\"] = pd.to_datetime(master_df[\"Date of BC\"], errors=\"coerce\")\n",
    "\n",
    "# Then we create a mask for rows with open access \n",
    "open_access_mask = master_df[\"Timepoint\"].str.lower().str.contains(\"open access\", na=False)\n",
    "\n",
    "# List to store the Timepoint values from the row immediately before the open access record.\n",
    "before_timepoints = []\n",
    "\n",
    "# Group by monkey ID  and process each monkey's records.\n",
    "for monkey, group in master_df.groupby(\"MATRR ID\"):\n",
    "    # Sort the monkey's records by date.\n",
    "    group_sorted = group.sort_values(\"Date of BC\").reset_index(drop=True)\n",
    "    \n",
    "    # Find indices where Timepoint indicates open access.\n",
    "    open_indices = group_sorted[group_sorted[\"Timepoint\"].str.lower().str.contains(\"open access\", na=False)].index\n",
    "    \n",
    "    # If at least one open access record exists, take the first one.\n",
    "    if len(open_indices) > 0:\n",
    "        first_open_index = open_indices[0]\n",
    "        # Check that there is a record before the open access row.\n",
    "        if first_open_index > 0:\n",
    "            before_row = group_sorted.iloc[first_open_index - 1]\n",
    "            before_timepoints.append(before_row[\"Timepoint\"])\n",
    "\n",
    "# Count how many times each Timepoint value appears as the \"before\" value.\n",
    "before_counts = pd.Series(before_timepoints).value_counts()\n",
    "print(before_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing there a lot of variety, for now well just use the record right before the open access and well record the monthly difference between teh before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Restrict master_df to the common monkey IDs only\n",
    "common_ids = set(master_df['MATRR ID'].unique()) & set(monkey_df['mky_id'].unique())\n",
    "master_common = master_df[master_df['MATRR ID'].isin(common_ids)].copy()\n",
    "\n",
    "# Initialize a list to hold the new rows.\n",
    "rows_list = []\n",
    "\n",
    "# Process each monkey group\n",
    "for monkey, group in master_common.groupby(\"MATRR ID\"):\n",
    "    # Sort the records by date\n",
    "    group_sorted = group.sort_values(\"Date of BC\").reset_index(drop=True)\n",
    "    # Look for the first occurrence of an \"open access\" record \n",
    "    for i in range(1, len(group_sorted)):\n",
    "        if \"open access\" in group_sorted.loc[i, \"Timepoint\"].lower():\n",
    "            # Use the record immediately preceding it as the \"before\"\n",
    "            before_row = group_sorted.iloc[i - 1].copy()\n",
    "            after_row = group_sorted.iloc[i].copy()\n",
    "            # Compute difference in months using relativedelta\n",
    "            before_date = before_row['Date of BC']\n",
    "            after_date = after_row['Date of BC']\n",
    "            delta = relativedelta(after_date, before_date)\n",
    "            # Approximate total months (include fractional month based on days)\n",
    "            months_diff = int(delta.years * 12 + delta.months + delta.days / 30.44)\n",
    "            \n",
    "            # Add new columns to indicate phase and month difference\n",
    "            before_row['phase'] = 'before'\n",
    "            before_row['months_diff'] = months_diff\n",
    "            after_row['phase'] = 'after'\n",
    "            after_row['months_diff'] = months_diff\n",
    "            \n",
    "            # Append both rows for this monkey and then break (only use the first open access occurrence)\n",
    "            rows_list.append(before_row)\n",
    "            rows_list.append(after_row)\n",
    "            break\n",
    "\n",
    "# Create the combined DataFrame\n",
    "combined_df = pd.DataFrame(rows_list)\n",
    "\n",
    "# Merge monkey-level info from monkey_df; rename mky_id to MATRR ID for consistency.\n",
    "monkey_info = monkey_df[['mky_id', 'mky_gender', 'mky_weight', 'drinking_category']].drop_duplicates()\n",
    "monkey_info = monkey_info.rename(columns={'mky_id': 'MATRR ID'})\n",
    "\n",
    "final_df = pd.merge(combined_df, monkey_info, on='MATRR ID', how='left')\n",
    "\n",
    "# Set a custom categorical order so that 'before' rows come before 'after'\n",
    "phase_order = ['before', 'after']\n",
    "final_df['phase'] = pd.Categorical(final_df['phase'], categories=phase_order, ordered=True)\n",
    "\n",
    "final_df = final_df.sort_values(['MATRR ID', 'phase']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('csv files/Before_After.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df['MATRR ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master['MATRR ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_master_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mclean_master_df\u001b[49m, biomarker_df, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMATRR ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Now we check the merged dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerged data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_master_df' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(clean_master_df, biomarker_df, left_on=\"MATRR ID\", right_on=\"ID\", how=\"left\")\n",
    "\n",
    "\n",
    "# Now we check the merged dataframe\n",
    "print(\"Merged data:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10016\n",
       "1      10018\n",
       "2      10019\n",
       "3      10020\n",
       "4      10021\n",
       "       ...  \n",
       "180    10346\n",
       "181    10343\n",
       "182    10349\n",
       "183    10345\n",
       "184    10348\n",
       "Name: MATRR ID, Length: 185, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['MATRR ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df['MATRR ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV saved as 'merged.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the merged dataframe if needed\n",
    "merged_df.to_csv(\"csv files/merged.csv\", index=False)\n",
    "print(\"Merged CSV saved as 'merged.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
